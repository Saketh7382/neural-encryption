{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from nltk.corpus import words\n",
    "import timeit\n",
    "import geocoder\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import binascii\n",
    "import pickle\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the corpus into CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = words.words()\n",
    "df = pd.DataFrame(data={\"Corpus\": corpus})\n",
    "df.to_csv(\"../datasets/corpus.csv\", sep=',',index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating bitcode to each word and Generating random language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_bits(text, encoding='utf-8', errors='surrogatepass'):\n",
    "    bits = bin(int(binascii.hexlify(text.encode(encoding, errors)), 16))[2:]\n",
    "    return bits.zfill(8 * ((len(bits) + 7) // 8))\n",
    "\n",
    "def text_from_bits(bits, encoding='utf-8', errors='surrogatepass'):\n",
    "    n = int(bits, 2)\n",
    "    return int2bytes(n).decode(encoding, errors)\n",
    "\n",
    "def int2bytes(i):\n",
    "    hex_string = '%x' % i\n",
    "    n = len(hex_string)\n",
    "    return binascii.unhexlify(hex_string.zfill(n + (n & 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_code = list()\n",
    "encrypted = list()\n",
    "\n",
    "for i in corpus:\n",
    "    bits = text_to_bits(i)\n",
    "    bit_code.append(bits)\n",
    "    t = np.random.randint(2, size= len(bits))\n",
    "    \"\".join(map(str, t))\n",
    "    t = \"\".join([str(a) for a in t])\n",
    "    encrypted.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"input\": bit_code, \"output\": encrypted})\n",
    "df.to_csv(\"../datasets/discriminatorData.csv\", sep=',',index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit = list()\n",
    "prediction = list()\n",
    "\n",
    "for i in bit_code:\n",
    "    bit.append(i)\n",
    "    prediction.append(1)\n",
    "    \n",
    "for i in encrypted:\n",
    "    bit.append(i)\n",
    "    prediction.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 = english language ; 0 = machine generated language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"bits\": bit, \"category\": prediction})\n",
    "df.to_csv(\"../datasets/training.csv\", sep=',',index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN Dataset Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_dataset = list()\n",
    "c = 0\n",
    "for i in corpus:\n",
    "    t = text_to_bits(i)\n",
    "    l = len(t)\n",
    "    k = 8 - (l%8)\n",
    "    if k != 24:\n",
    "        s = ''\n",
    "        for j in range(k):\n",
    "            s = s + \"0\"\n",
    "        t = s + t\n",
    "    \n",
    "    s = textwrap.wrap(t,8)\n",
    "    ann_dataset.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = list( dict.fromkeys(final) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "a = string.printable\n",
    "ascii_list = list()\n",
    "for i in a:\n",
    "    ascii_list.append(text_to_bits(i))\n",
    "encrypted = list()\n",
    "c = 1\n",
    "for i in ascii_list:\n",
    "    t = np.random.randint(2, size= 8)\n",
    "    \"\".join(map(str, t))\n",
    "    t = \"\".join([str(a) for a in t])\n",
    "    if t in encrypted or t in ascii_list:\n",
    "        flag = 1\n",
    "        while flag:\n",
    "            t = np.random.randint(2, size= 8)\n",
    "            \"\".join(map(str, t))\n",
    "            t = \"\".join([str(a) for a in t])\n",
    "            if t in encrypted or t in ascii_list:\n",
    "                flag = 1\n",
    "            else:\n",
    "                encrypted.append(t)\n",
    "                flag = 0\n",
    "    else:\n",
    "        encrypted.append(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"input\": ascii_list, \"output\": encrypted})\n",
    "df.to_csv(\"../datasets/ascii.csv\", sep=',',index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "final = list(itertools.chain.from_iterable(ann_dataset))\n",
    "next_row = list(itertools.chain.from_iterable(ann_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mylist = list( dict.fromkeys(final) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u0000\n",
      "\n",
      "A\n",
      "\n",
      "a\n",
      "\n",
      "l\n",
      "\n",
      "i\n",
      "\n",
      "m\n",
      "\n",
      "n\n",
      "\n",
      "r\n",
      "\n",
      "d\n",
      "\n",
      "v\n",
      "\n",
      "k\n",
      "\n",
      "w\n",
      "\n",
      "o\n",
      "\n",
      "f\n",
      "\n",
      "c\n",
      "\n",
      "t\n",
      "\n",
      "e\n",
      "\n",
      "u\n",
      "\n",
      "b\n",
      "\n",
      "h\n",
      "\n",
      "y\n",
      "\n",
      "s\n",
      "\n",
      "p\n",
      "\n",
      "g\n",
      "\n",
      "z\n",
      "\n",
      "x\n",
      "\n",
      "j\n",
      "\n",
      "q\n",
      "\n",
      "B\n",
      "\n",
      "C\n",
      "\n",
      "D\n",
      "\n",
      "E\n",
      "\n",
      "F\n",
      "\n",
      "G\n",
      "\n",
      "H\n",
      "\n",
      "I\n",
      "\n",
      "J\n",
      "\n",
      "-\n",
      "\n",
      "P\n",
      "\n",
      "K\n",
      "\n",
      "L\n",
      "\n",
      "M\n",
      "\n",
      "N\n",
      "\n",
      "O\n",
      "\n",
      "Q\n",
      "\n",
      "R\n",
      "\n",
      "S\n",
      "\n",
      "T\n",
      "\n",
      "U\n",
      "\n",
      "V\n",
      "\n",
      "W\n",
      "\n",
      "X\n",
      "\n",
      "Y\n",
      "\n",
      "Z\n"
     ]
    }
   ],
   "source": [
    "for i in mylist:\n",
    "    print(text_from_bits(i))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next_row.pop(0)\n",
    "next_row.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={\"first word\": final, \"next word\": next_row})\n",
    "df.to_csv(\"../datasets/ann_dataset.csv\", sep=',',index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating discriminator model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "df = pd.read_csv('../datasets/training.csv')\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,[0]], df.iloc[:,[1]], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cp/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../models/discriminator.sav'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
